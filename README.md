# ğŸ§  Multimodal Fake News Detection System

This project implements a **multimodal fake news detection system** capable of analyzing **text, images, videos, and web links**.  
It extracts verifiable claims, retrieves evidence from trusted sources, evaluates semantic similarity, and produces an explainable credibility verdict.

The system is designed as an **academic MCA-level project**, focusing on modularity, explainability, and real NLP techniques.

---

## ğŸ“Œ System Overview

The system follows a unified verification pipeline:

**Input â†’ Claim Extraction â†’ Claim Normalization â†’ Evidence Retrieval â†’ Verification â†’ Explanation â†’ Verdict**

Supported input types:
- ğŸ“ Text
- ğŸ–¼ï¸ Image
- ğŸ¥ Video
- ğŸ”— News / social media links

---

## ğŸ—ï¸ Project Structure

Multi_Modal_Fake_News_Detection/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI application entry point
â”‚ â”œâ”€â”€ pipeline.py # Central orchestration pipeline
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ claim_from_text.py # Claim extraction from text using transformers
â”‚ â”œâ”€â”€ claim_from_image.py # OCR + claim extraction from images
â”‚ â”œâ”€â”€ claim_from_video.py # Audio extraction + speech-to-text + claim extraction
â”‚ â”œâ”€â”€ evidence_retrieval.py# Evidence retrieval from trusted sources
â”‚ â”œâ”€â”€ verification.py # Semantic similarity based verification
â”‚ â”œâ”€â”€ explanation.py # Explanation generation
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ scrap_text_from_link.py # Web article text extraction
â”‚ â”œâ”€â”€ claim_normalizer.py # Claim cleaning and query normalization
â”‚ â””â”€â”€ init.py
â”‚
â”œâ”€â”€ uploads/ # Temporary storage for uploaded files
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ” Processing Pipeline

### 1ï¸âƒ£ Input Handling
- Handled via **FastAPI** (`app/main.py`)
- Accepts text, file uploads, or URLs
- Routes input based on modality

---

### 2ï¸âƒ£ Claim Extraction
| Modality | Method |
|--------|--------|
| Text | Abstractive summarization using transformer models |
| Image | OCR â†’ summarized claim |
| Video | Audio extraction â†’ speech-to-text â†’ summarized claim |
| Link | Web scraping â†’ summarized claim |

Goal: extract a **short, factual, verifiable claim**.

---

### 3ï¸âƒ£ Claim Normalization
- Removes noise and extra clauses
- Keeps claims within API length limits
- Relaxes queries when evidence retrieval fails

---

### 4ï¸âƒ£ Evidence Retrieval
- Queries Wikipedia and trusted sources
- Extracts multiple evidence snippets
- Assigns trust scores per source

---

### 5ï¸âƒ£ Claim Verification
- Uses **semantic similarity** (Sentence Transformers)
- Compares extracted claim with retrieved evidence
- Outputs similarity score and verdict label

Possible labels:
- **Supported**
- **Refuted**
- **Uncertain**

---

### 6ï¸âƒ£ Explanation Generation
- Selects the strongest evidence
- Produces a human-readable explanation
- Explains why a claim is real, fake, or uncertain

---

### 7ï¸âƒ£ Final Output
json
{
  "claim": "Narendra Modi is President of Bihar",
  "verdict": "Fake",
  "confidence": 0.23,
  "explanation": "Evidence contradicts the claim..."
}
###ğŸš€ How to Run the Project
1ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
2ï¸âƒ£ Start the FastAPI server
bash
Copy code
uvicorn app.main:app --reload
3ï¸âƒ£ Access the API
cpp
Copy code
http://127.0.0.1:8000
###ğŸ¯ Key Features
Multimodal fake news analysis

Modular and extensible architecture

Semantic (meaning-based) verification

Explainable AI outputs

Academic-project friendly design

###âš ï¸ Limitations
Evidence retrieval mainly relies on Wikipedia

OCR and speech-to-text accuracy depends on input quality

No social media metadata analysis

Claim extraction uses summarization instead of fine-tuned claim models

###ğŸ”® Future Enhancements
Zero-shot and NLI-based verification

Source credibility and social context scoring

Multilingual support

Knowledge graph integration

Fine-tuned claim extraction models

###ğŸ“ Intended Use
This project is intended for:

MCA / academic final-year projects

Research demonstrations

Learning multimodal NLP pipelines

It is not intended for production deployment.
